<!DOCTYPE html>
<html>
<head>
    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Page Meta -->
    <title>[머신러닝] 딥러닝 영화 개인화 추천 - Part.2</title>
    <meta name="description" content="A beautiful narrative written with the world's most elegant publishing platform. The story begins here." />

    <!-- Mobile Meta -->
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <!-- Brand icon -->
    <link rel="shortcut icon" href="/assets/images/favicon.ico" >

    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
    <link rel="stylesheet" type="text/css" href="/assets/css/syntax.css" />

    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!-- Ghost outputs important style and meta data with this tag -->
        <link rel="canonical" href="//movie-dlrm-2" />
    <meta name="referrer" content="origin" />
    <link rel="next" href="/page2/" />

    <meta property="og:site_name" content="코딩만 잘하면 될까?" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="[머신러닝] 딥러닝 영화 개인화 추천 - Part.2" />
    <meta property="og:description" content="A beautiful narrative written with the world's most elegant publishing platform. The story begins here." />
    <meta property="og:url" content="//movie-dlrm-2" />
    <meta property="og:image" content="/assets/images/cover6.jpg" />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="[머신러닝] 딥러닝 영화 개인화 추천 - Part.2" />
    <meta name="twitter:description" content="A beautiful narrative written with the world's most elegant publishing platform. The story begins here." />
    <meta name="twitter:url" content="//movie-dlrm-2" />
    <meta name="twitter:image:src" content="/assets/images/cover6.jpg" />

    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Website",
    "publisher": "코딩만 잘하면 될까?",
    "name": "[머신러닝] 딥러닝 영화 개인화 추천 - Part.2",
    "url": "//movie-dlrm-2",
    "image": "/assets/images/cover6.jpg",
    "description": "A beautiful narrative written with the world's most elegant publishing platform. The story begins here."
}
    </script>

    <meta name="generator" content="Jekyll 3.0.0" />
    <link rel="alternate" type="application/rss+xml" title="코딩만 잘하면 될까?" href="/feed.xml" />


    
</head>
<body class="home-template nav-closed">

    <!-- The blog navigation links -->
    <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        <li class="nav-home " role="presentation"><a href="/">Home</a></li>
        <li class="nav-about " role="presentation"><a href="/about">About</a></li>
        <li class="nav-algorithms " role="presentation"><a href="/tag/algorithms">Algorithms</a></li>
        <li class="nav-database " role="presentation"><a href="/tag/database">Database</a></li>
	<li class="nav-github " role="presentation"><a href="/tag/github">Github</a></li>
        <li class="nav-java " role="presentation"><a href="/tag/java">Java</a></li>	
        <li class="nav-woowacourse " role="presentation"><a href="/tag/wooowacourse">우아한테크코스</a></li>
	<li class="nav-daily " role="presentation"><a href="/tag/daily">잡동사니</a></li>
	<li class="nav-machinelearning " role="presentation"><a href="/tag/machinelearning">Machine Learning</a></li>
	<li class="nav-author " role="presentation"><a href="/author/yj">YJ</a></li>
    </ul>
    <a class="subscribe-button icon-feed" href="/feed.xml">Subscribe</a>
</div>
<span class="nav-cover"></span>


    <div class="site-wrapper">

        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The comment above "< default" means - insert everything in this file into -->
    <!-- the [body] of the default.hbs template, which contains our header/footer. -->

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<header class="main-header post-head " style="background-image: url(/assets/images/cover6.jpg) ">
    <nav class="main-nav  overlay  clearfix">
        <a class="blog-logo" href="/"><img src="/assets/images/ghost.png" alt="Blog Logo" /></a>
        
            <a class="menu-button icon-menu" href="#"><span class="word">Menu</span></a>
        
    </nav>
</header>

<main class="content" role="main">

    <article class="post tag-machinelearning">

        <header class="post-header">
            <h1 class="post-title">[머신러닝] 딥러닝 영화 개인화 추천 - Part.2</h1>
            <section class="post-meta">
            <!-- <a href='/'></a> -->

            
                
            
                
            
                
            
                
            
                
            
                
            
                
                    <a href='/author/yj'>YJ's Dev Journals</a>
                
            
            <time class="post-date" datetime="2020-08-22">22 Aug 2020</time>
                <!-- [[tags prefix=" on "]] -->
                
                on
                
                    
                       <a href='/tag/machinelearning'>Machinelearning</a>
                    
                
                
            </section>
        </header>

        <section class="post-content">

            <p>이어서 딥러닝 영화 개인화 추천 모델을 구현하면서 구축한 딥러닝 협업 필터링 모델 부분에 대한 코드를 살펴보면서 딥러닝 전체적인 흐름에 대해서 짚어보자. 앞에서 언급했듯이 코드는 다음 <a href="https://jyoondev.tistory.com/65?category=823946">링크</a>에서 참고하여 모델과 전체적인 데이터 처리를 진행했고, 이후에 학습된 output에 대한 데이터 및 결과 후처리는 추가 구현했다. 해당 부분은 다음 파트에 다루도록 하겠다.</p>

<h3 id="모델-전체-코드">모델 전체 코드</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">NNCollabFiltering</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_users</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">emb_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">NNCollabFiltering</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">user_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_users</span><span class="p">,</span> <span class="n">emb_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">item_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_items</span><span class="p">,</span> <span class="n">emb_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">emb_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">drop1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
    
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_emb</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_emb</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<h3 id="step1-임베딩---nnembedding">Step1. 임베딩 - nn.Embedding()</h3>

<p>위 코드를 보면 먼저 User와 Item에 관한 임베딩으로 시작한다. 파이토치에서 임베딩 벡터를 사용하는 방법은 크게 두가지가 있는데 그 중 위의 <code class="highlighter-rouge">nn.Embedding()</code> 은 embedding layer를 만들어서 훈련 데이터로부터 처음부터 임베딩 벡터를 학습하는 방법이다.</p>

<p>먼저 임베딩 층의 입력으로 사용하기 위해서는 정수 인코딩이 되어 있어야 한다. 즉 다음과 같은 단계를 따른다.</p>

<blockquote>
  <p>어떤 단어 -&gt; 고유한 정수로 인코딩 -&gt; 임베딩 층을 통과 -&gt; 밀집 벡터</p>
</blockquote>

<p>즉, 고유한 정수 인코딩 값에 대해서 밀집 벡터(dense vector)를 맵핑해주는 것이다. 이 밀집 베터가 흔히 알고 있는 임베딩 벡터이다. 임베딩을 시킨다는 것은 어떠한 단어에 대한 고유 인코딩 정수값을 인덱스로 가지고 있는 룩업 테이블에서 해당 임베딩 벡터 값을 가져오는 것이다. 또한 <mark>이 테이블은 단어 집합만큼의 행을 가지고 있으므로 모든 단어들은 고유한 임베딩 벡터를 보유하게 된다.</mark> 이러한 벡터 값을 담고 있는 룩업 테이블을 생성하는 것이 <code class="highlighter-rouge">nn.Embedding()</code>의 역할이다.</p>

<p><img src="https://user-images.githubusercontent.com/63405904/110482824-6bad5d80-812c-11eb-9da2-750e1946c80b.png" alt="image" /></p>

<p>위의 그림을 참고해보면 단어 ‘great’에 대한 임베딩 벡터가 4차원인 것을 확인할 수 있다. 해당 차원값은 parameter로 넘겨줄 수 있는 부분이다. 이렇게 생성된 임베딩 벡터는 모델의 입력이 되고, 역전파 과정을 거치면서 바로 이 임베딩 벡터값이 학습 되는 것이다.</p>

<h5 id="-코드에서-임베딩">&gt; 코드에서 임베딩</h5>

<p>위 코드에서 임베딩이 어떻게 이루어지고 있는지 살펴보자. 코드를 살펴보면 임베딩 관련한 부분에 다음과 같이 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#def __init__ 메소드 내: </span>
  <span class="bp">self</span><span class="o">.</span><span class="n">user_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_users</span><span class="p">,</span> <span class="n">emb_size</span><span class="p">)</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">item_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_items</span><span class="p">,</span> <span class="n">emb_size</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">nn.Embedding()</code> 에 넘겨지는 parameter는 크게 <strong>2가지</strong>가 있다. 1) 테이블 사이즈 (단어 및 데이터 갯수) 2) 임베딩 사이즈 (embedding vector  차원).</p>

<p>영화에서 모델에 넣어서 학습할 데이터는 사용자 user와 영화 item이다. 이 두개에 대한 임베딩 테이블을 생성하기 위해서 인코딩 하며 중복없이 뽑아낸 user 와 item 리스트의 크기와 임베딩 사이즈를 결정해서 <code class="highlighter-rouge">nn.Embbeding()</code>을 호출한다. 그럼 임베딩 테이블이 생성되어 각각 user_emb 와 item_emb에 저장된다.</p>

<h3 id="step2-linear-layer-생성---nnlinear">Step2. Linear Layer 생성 - nn.Linear()</h3>

<p>다음 코드에서는 Linear layer를 생성한다. 딥러닝의 핵심인 신경망(neural network) 층을 쌓아올려서 학습을 진행한다. 그때 필요한 신경망 층을 생성하는 역할을 한다. 딥러닝을 위한 신경망은 기본적으로 선형회귀분석을 기본으로 하기 때문에 선형변형 함수로 층을 쌓는다.</p>

<p><img src="https://user-images.githubusercontent.com/63405904/110482886-7d8f0080-812c-11eb-9b12-6c65a734be69.png" alt="image" /></p>

<p>파이토치에서 제공하는 <a href="https://pytorch.org/docs/stable/nn.html#linear-layers">document</a>를 살펴보면 위와 같은 선형변형 함수를 사용하는 것을 확인할 수 있다. 선형결합은 보존하는 선형변형 함수를 생성하고 원하는 <strong>in_feature</strong>와 <strong>out_feature</strong>의 사이즈를 parameter로 넘긴다.</p>

<h5 id="-코드에서-layer-생성">&gt; 코드에서 layer 생성</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#def __init__ 메소드 내:</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">lin1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">emb_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>위 코드는 입력 차원이 emb_size의 두배인 input sample에 대해서 n_hidden 사이즈 만큼의 차원으로 선형변형을 하는 linear layer 하나와, n_hidden 사이즈의 input sample에 대해서 1로 선형변형을 하는 linear layer 두개를 생성한다.</p>

<h3 id="step3-모델-일반화---nndropout">Step3. 모델 일반화 - nn.Dropout()</h3>

<p>Dropout은 모델을 일반화 기법으로 일부 파라미터를 학습에 반영하지 않는 것이다. Validation과 test 시에는 적용하지 않고 train 시에 dropout을 적용하는데, 일종의 정규화 기법이라고 볼 수 있다. 모델을 학습할 때 과적합(overfitting)의 위험을 줄이고, 학습속도를 개선하는 문제를 해결하기 위한 방법이다. 모델을 학습할 때 지나치게 학습 데이터에 대한 높은 정확도를 보이기 보다, 범용적으로 사용될 수 있도록 overfitting 문제를 피하기 위해서 고안된 해결책 중 하나이다. 일반적으로 신경망의 층이 깊어지고, 학습률이 작을수록 overfitting이 될 가능성이 높다.</p>

<p>이중 본 코드에서 사용하고 있는 모델 일반화의 방법은 드롭아웃 Dropout이다. 신경망 모델이 지나치게 복잡해질 때, 뉴런의 연결을 임의로 삭제하여 전달하지 않도록 떨어뜨리는 역할을 한다. 다만, 테스트를 할 때에는 모든 뉴런을 사용하기 때문에 반드시 학습시에만 드롭아웃을 적용해야 한다.</p>

<p><img src="https://user-images.githubusercontent.com/63405904/110482706-47ea1780-812c-11eb-9908-5686512aae8c.png" alt="image" /></p>

<p>파이토치 <a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout">document</a>를 보면 <code class="highlighter-rouge">nn.torch</code> 모듈에서 드롭아웃 또한 지원을 한다.</p>

<p><img src="https://user-images.githubusercontent.com/63405904/110482789-5fc19b80-812c-11eb-960c-8f7da3b2597f.png" alt="image" /></p>

<p>파이토치에 제공하는 도큐멘트를 살펴보면 학습시 무작위로 몇개의 뉴런들에 대해서 <em>p</em> 확률만큼  ‘zeros’ 시킨다고 나와있다. 이때 <em>p</em>는 parameter로 주어지는 확률 변수이고, default는 0.5이다. <code class="highlighter-rouge">forward</code>함수가 호출될 때마다 적용되도록 되어 있다.</p>

<h5 id="-코드에서-dropout">&gt; 코드에서 Dropout</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#def __init__ 메소드 내:</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">drop1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
</code></pre></div></div>

<p>본 코드를 살펴보면 nn.torch 모둘에서 Dropout 함수를 호출하고 확률 변수를 0.1로 주었다.</p>

<h3 id="step4-활성화함수---torchnnfunctionalrelu">Step4. 활성화함수 - torch.nn.functional.relu()</h3>

<p>다음 딥러닝 신경망 모델 구축에서 중요한 부분은 활성화 함수(Activation Function)이다. 활성화 함수는 최종출력 신호 후, 다음 뉴런으로 보낼지 말지를 결정하는 함수이다. 즉, 특정 뉴런이 다음 뉴런으로 신호를 보낼 때 입력신호의 어떠한 기준에 따라서 보내고 보내지 않는지를 결정하도록 하는 것이다. 딥러닝에서는 뉴런들을 다음 레이어로 전달할 때 비선형 함수를 통화시킨 후 전달하도록 하는데 이때 사용되는 함수가 활성화 함수이다.</p>

<p>딥러닝 학습의 핵심은 이름에서 볼 수 있듯이 깊게 층을 쌓아서 그 층을 통과하면서 학습되는 것인데, 선형함수를 사용하게 되면 층을 깊게 하는 의미가 줄어들게 된다. 해당 설명은 [밑바닥부터 시작하는 딥러닝] 책의 한 부분을 인용하도록 하겠다.</p>

<blockquote>
  <p>선형합수인 h(x)=cx를 활성화함수로 사용한 3층 네트워크를 떠올려 보세요. 이를 식으로 나타내면 y(x) = h(h(h(x)))가 됩니다. 이는 실은 y(x)=ax와 똑같은 식 입니다. a=c3이라고 하면 끝이죠. 즉, 은닉층이 없는 네트워크로 표현할 수 있습니다. 뉴럴네트워크에서 층을 쌓는 혜택을 얻고 싶다면 활성화 함수로는 반드시 비선형 함수를 사용해야 한다.</p>

  <p>-밑바닥부터 시작하는 딥러닝-</p>
</blockquote>

<p>이러한 역할을 하는 활성화 함수는 많은 종류가 있다. <strong>1) 시그모이드 함수 2) tanh 함수 3) ReLU 함수.</strong>  본 코드에서는 가장 많이 사용되는 활성화 함수인 ReLU 함수를 사용했다.</p>

<p><img src="https://user-images.githubusercontent.com/63405904/110482937-8b448600-812c-11eb-9672-04dc7c7e5928.png" alt="image" /></p>

<p>ReLU 함수를 살펴보면 $x &gt; 0$ 이면 기울기가 1인 직선이고 $x &lt; 0$이면 함수값이 0이 된다. 따라서 다른 활성화함수에 비해서 굉장히 간단하고 빠르다. 해당 함수는 양수에서는 Linear function 과 같은 모습을 보이지만 음수의 경우 0으로 버려지므로 non-linear 한 함수로 작동하여 layer를 깊게 쌓을 수 있는 장점을 가진다.</p>

<h5 id="-코드에서-활성화함수">&gt; 코드에서 활성화함수</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#def forward 내</span>
	<span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<p>선형함수가 linear layer에 들어가기 전에 비선형 함수를 거친다. 위의 코드에서 F는 <code class="highlighter-rouge">torch.nn.funtional</code>모듈이며 모듈 내에 있는 <code class="highlighter-rouge">relu()</code>를 사용하고 있다.</p>

<p><strong><small> [참고 자료]: https://wikidocs.net/64779, https://tutorials.pytorch.kr/beginner/blitz/neural_networks_tutorial.html, https://pytorch.org/docs/, https://yeomko.tistory.com/39, https://reniew.github.io/12/, https://eda-ai-lab.tistory.com/405, https://jyoondev.tistory.com/65?category=823946, https://sacko.tistory.com/45</small></strong></p>



        </section>

        <footer class="post-footer">

            <!-- Everything inside the #author tags pulls data from the author -->
            <!-- #author-->
            
                
            
                
            
                
            
                
            
                
            
                
            
                
                    
                        <figure class="author-image">
                            <a class="img" href="/author/yj" style="background-image: url(/assets/images/yj.png)"><span class="hidden">yj's Picture</span></a>
                        </figure>
                    

                    <section class="author">
                        <h4><a href="/author/yj">YJ's Dev Journals</a></h4>

                        
                            <p> 개발자는 코딩만 잘하면 돼!! 를 탈피하기 위해 우선 코딩을 잘하고자 하는 예비 개발자</p>
                        
                        <div class="author-meta">
                            <span class="author-location icon-location"> 개발개발, 개발</span>
                            <span class="author-link icon-link"><a href="http://yjksw.github.io/"> yjksw.github.io</a></span>
                        </div>
                    </section>

                    <!-- /author  -->

                    <section class="share">
                        <h4>Share this post</h4>
                        <a class="icon-twitter" href="http://twitter.com/share?text=[머신러닝] 딥러닝 영화 개인화 추천 - Part.2&amp;url=movie-dlrm-2"
                            onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                            <span class="hidden">Twitter</span>
                        </a>
                        <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=movie-dlrm-2"
                            onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                            <span class="hidden">Facebook</span>
                        </a>
                        <a class="icon-google-plus" href="https://plus.google.com/share?url=movie-dlrm-2"
                           onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                            <span class="hidden">Google+</span>
                        </a>
                    </section>
                
            

            <!-- Add Disqus Comments -->
            

        </footer>

    </article>

</main>

<aside class="read-next">

    <!-- [[! next_post ]] -->
    
        <a class="read-next-story " style="background-image: url(/assets/images/cover6.jpg)" href="/movie-dlrm-3">
            <section class="post">
                <h2>[머신러닝] 딥러닝 영화 개인화 추천 - Part.3</h2>
                <p>영화 개인화 추천 포스트의 마지막 파트이다. 이전까지는 데이터를 입력받아서 전처리하고, 모델을 구축하여 학습의 원리에 대해서...</p>
            </section>
        </a>
    
    <!-- [[! /next_post ]] -->
    <!-- [[! prev_post ]] -->
    
        <a class="read-next-story prev " style="background-image: url(/assets/images/cover6.jpg)" href="/movie-dlrm-1">
            <section class="post">
                <h2>[머신러닝] 딥러닝 영화 개인화 추천 - Part.1</h2>
                <p>인턴을 하는 중에 요즘에 중요한 머신러닝의 한 분야가 되고 있는 개인화 추천에 대한 개발을 맡게...</p>
            </section>
        </a>
    
    <!-- [[! /prev_post ]] -->
</aside>

<!-- /post -->


        <!-- The tiny footer at the very bottom -->
        <footer class="site-footer clearfix">
          <section class="copyright"><a href="/">코딩만 잘하면 될까?</a> &copy; 2021</section>
          <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> using <a href="https://github.com/jekyller/jasper">Jasper</a></section>
        </footer>
    </div>
    <!-- highlight.js -->
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- jQuery needs to come before `` so that jQuery can be used in code injection -->
    <script type="text/javascript" src="//code.jquery.com/jquery-1.12.0.min.js"></script>
    <!-- Ghost outputs important scripts and data with this tag -->
    <!--  -->
    <!-- Add Google Analytics  -->
        <!-- Google Analytics Tracking code -->
     <script>
	    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	    ga('create', 'UA-69281367-1', 'auto');
	    ga('send', 'pageview');

     </script>
    <!-- Fitvids makes video embeds responsive and awesome -->
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <!-- The main JavaScript file for Casper -->
    <script type="text/javascript" src="/assets/js/index.js"></script>

</body>
</html>
