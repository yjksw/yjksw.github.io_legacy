<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>yjksw.github.io/</title>
   
   <link></link>
   <description>A beautiful narrative written with the world's most elegant publishing platform. The story begins here.</description>
   <language>en-uk</language>
   <managingEditor> </managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>재귀 vs. 반복</title>
	  <link>//recursion</link>
	  <author></author>
	  <pubDate>2021-02-26T10:18:00+00:00</pubDate>
	  <guid>//recursion</guid>
	  <description><![CDATA[
	     <p><strong>Binary Search</strong> 이분탐색을 구현하면서, 계속 런타임 에러가 났다. 처음에 재귀로 구현을 시작했는데, 재귀에 너무 큰 값이 들어오면서 stack overflow 에러가 났나 싶어서 다시 while 문으로 구현했다. 하지만 while 문으로 구현한 이후에도 계속 런타임 에러가 떠서 확인해보니, n과 m을 헷갈려서 잘못 적었던 것이었다.</p>

<p>이왕 while 문으로 구현해서 맞은 거, 재귀와 비교해 보자 해서 재귀를 돌려 보았더니, 재귀가 훨씬 빠르고 메모리 효율도 좋은 것이었다. 일반적으로 생각했을 때, 재귀는 매번 메모리를 할당하면서 새로운 함수를 call 해주어야 하고, 또 그만큼의 시간과 공간이 더 필요해서 반복문에 비해 성능이 다소 떨어진다고 알고 있었지만, 훨씬 빠르고 메모리 효율도 좋아서 그 이유에 대해서 찾아보게 되었다. 정답은 <strong>Tail-recursion.</strong></p>

<h2 id="tail-recursion">Tail-Recursion</h2>

<h3 id="tail-recursion이란">Tail-Recursion이란?</h3>

<p>Tail-Recursion이란 recursion 함수에서 가장 나중에 실행되는 명령어를 뜻한다. 마지막 시행 명령이 재귀 호출이라면, 해당 함수는 tail-recursion의 형태를 가지고 있다고 할 수 있다.</p>

<h3 id="tail-recursion의-효능">Tail-Recursion의 효능</h3>

<p>Tail-recursion은 주로 non tail recursion에 비교해서 성능이 더 좋은 것으로 나타난다. 마지막 recursion을 call 하고, 해당 호출에 연산이 포함되어 있지 않는다면 컴파일러에 의해서 해당 tail-recursion 함수는 optimize 된다. 이 이유는, tail-recursion 함수의 경우, 함수의 가장 마지막으로 실행하는 것이 recursive call이기 때문에 현재 머물고 있는 함수에 더 이상 진행할 instruction이 없고 따라서 현재 함수를 stack에 저장하지 않아도 된다. 때문에 non tail recursion 보다 더 빠르고, stack 메모리를 사용하지 않는 장점을 지닌다.</p>

<p>주의할 것은 다음과 같이 마지막에 recursive 함수 호출은 한다고 하더라도, 연산이 끼어 있다면, optimize 될 수 없다.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">static</span> <span class="kt">int</span> <span class="nf">fac</span><span class="o">(</span><span class="kt">int</span> <span class="n">num</span><span class="o">){</span>
	<span class="k">if</span><span class="o">(</span><span class="n">num</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span>
		<span class="k">return</span> <span class="mi">1</span><span class="o">;</span>
	
	<span class="k">return</span> <span class="n">n</span><span class="o">*</span><span class="n">fac</span><span class="o">(</span><span class="n">num</span><span class="o">-</span><span class="mi">1</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<h3 id="결과-비교">결과 비교</h3>

<p>백준 이분 탐색을 풀었을 때 결과 화면이다.</p>

<p>첫번째 실행이 tail recursion을 사용하여 구현했을 때이고, 두번째가 while 반복문을 사용하여서 구현한 것인데 tail recursion이 재귀를 사용했음에도 불구하고 그 시간이 현저히 빠르고 메모리 효율 또한 좋은 것을 확인할 수 있다.</p>

<p><img src="%E1%84%8C%E1%85%A2%E1%84%80%E1%85%B1%20vs%20%E1%84%87%E1%85%A1%E1%86%AB%E1%84%87%E1%85%A9%E1%86%A8%20cdf97d3b5b144477a10068a6f868ddaf/baekResult.png" alt="%E1%84%8C%E1%85%A2%E1%84%80%E1%85%B1%20vs%20%E1%84%87%E1%85%A1%E1%86%AB%E1%84%87%E1%85%A9%E1%86%A8%20cdf97d3b5b144477a10068a6f868ddaf/baekResult.png" /></p>


	  ]]></description>
	</item>

	<item>
	  <title>[머신러닝]나이브 베이즈 분류기(Naive Bayes Classifier)</title>
	  <link>//naivebayes</link>
	  <author></author>
	  <pubDate>2021-02-26T10:18:00+00:00</pubDate>
	  <guid>//naivebayes</guid>
	  <description><![CDATA[
	     <p>강남의 어느 검색 솔루션 기업에서 인턴한지 어연 4주차가 지나간다. 중간지점을 지나가면서 한 것을 정리할 겸 나이브베이즈 문서 분류기 구현과 이론에 대해서 정리해 보려고 한다. 최대한 쉽게!!</p>

<p>나이브 베이즈 분류기는 베이즈 정리(Bayes’ theorem)을 사용한 분류
알고리즘이다. 이것은 전통적으로 텍스트 분류를 하는 분류기로 인공지능의
기능을 기학적으로 올려준 인공 신경망 알고리즘은 아니지만 머신 러닝의
중요한 알고리즘 중 하나로 꽤 좋은 성능을 보인다. 나이브 베이즈
분류기에서 사용하는 베이즈 정리는 무엇일까?</p>

<p><a href="#%EB%B2%A0%EC%9D%B4%EC%A6%88%EC%9D%98-%EC%A0%95%EB%A6%ACbayes-theorem%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%9C-%EB%B6%84%EB%A5%98-%EA%B8%B0%EB%B2%95"></a></p>

<p>베이즈의 정리(Bayes’ theorem)를 사용한 분류 기법</p>

<p>베이즈 정리는 조건부 확률을 계산하는 방법 중 하나이다. 다음과 같이
표현할 수 있다.</p>

<ul>
  <li><strong><em>P(A)</em></strong>: 사전확률(Prior). 사건 B가 발생하기 전 A가 가지고 있던
확률</li>
  <li><strong><em>P(B)</em></strong>: 정규화 상수(normalizing constant). B가 일어날 확률</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>***P(B</td>
          <td>A)***: 가능도(likelihood). A가 발생한 경우 B가 일어날 확률</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>***P(A</td>
          <td>B)***: 사후확률(Posterior). B가 발생한 후 A가 일어날 확률</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<table>
  <tbody>
    <tr>
      <td>이 때 ***P(A</td>
      <td>B)***를 구하려면, 다음과 같은 수식을 사용한다.</td>
    </tr>
  </tbody>
</table>

<p>P(A∣B)=P(B∣A)P(A)P(B)P(A|B) = \frac {P(B|A)P(A)}
{P(B)}P(A∣B)=P(B)P(B∣A)P(A)​</p>

<p>주로 나이브 베이즈 분류기법을 설명할 때 스팸 메일 분류기를 예를 들어서
설명한다.</p>

<p><a href="#%EB%82%98%EC%9D%B4%EB%B8%8C-%EB%B2%A0%EC%9D%B4%EC%A6%88%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%8A%A4%ED%8C%B8-%EB%B6%84%EB%A5%98%EA%B8%B0"></a></p>

<p>나이브 베이즈를 활용한 스팸 분류기</p>

<p>어떤 문서 D에 대하여 해당 문서가 스팸(S)클래스에 속하는지
일반(!S)클래스에 속하는지 분류할 때 나이브 베이즈 분류 알고리즘을
사용한다고 하자. 그리고 이미 각기 다른 단어들에 대해서 해당 단어가
스팸일 확률과 일반일 확률에 대한 데이터가 이미 확보되어 있다고 가정한다.
한번 기호로 살펴보자. 우리가 가지고 있는 데이터는 다음 두개와 같다.
다음은 각각 “Sale이라는 단어는 60%의 확률로 스팸메일에서 발견되고, 30%의
확률로 일반메일에 발견된다.”라는 정보를 가지고 있는 것이다.</p>

<table>
  <tbody>
    <tr>
      <td>P(′Sale′∣S),P(′Sale′∣!S)P(‘Sale’</td>
      <td>S),</td>
    </tr>
    <tr>
      <td>P(‘Sale’</td>
      <td>!S)P(′Sale′∣S),P(′Sale′∣!S)</td>
    </tr>
  </tbody>
</table>

<p>데이터를 수 만개의 단어들에 대한 위의 데이터를 활용해서 결국 풀고 싶은
문제는 P(S∣D)P(S|D)P(S∣D)와 P(!S∣D)P(!S|D)P(!S∣D)이다. 다음 두 확률을
구한 다음 확률이 더 큰 클래스에 해당 문서가 속한다고 결론을 내린다.
P(S∣D)P(S|D)P(S∣D)는 문서 DDD가 주어졌다는 가정하에 해당 문서가 스팸일
조건부 확률을 나타낸다. 반대로 P(!S∣D)P(!S|D)P(!S∣D)는 문서 DDD가
주어졌다는 가정하에 해당 문서가 스팸이 아닐 조건부 확률을 나타낸다. 해당
문서를 어떤 클래스에 속하는지 분류하려면 먼저 문서에서 feature를
추출해야 한다. 추출된 feature들이 어떤 규칙에 의한 키워드 단어들이라고
할 때, 베이즈 정리는 특징벡터x=(x1,x2,…,xn)x=(x1, x2, …,
xn)x=(x1,x2,…,xn)의 요소들이 모두 <strong>조건부 독립</strong>이라는 가정을 한다.
즉, 각 단어들이 서로 미치는 확률에 있어서 연관이 없다고 가정하는 것이다.
(이 부분에서 ‘Naive(순진한) ‘라는 이름이 붙는다. 실제로는 모두
독립적이지 않고 동등하지 않은데 이렇게 간주해버리는 순진함을 가지고
있다.) 이때 해당 특징벡터 xxx에 대한 클래스 SSS에 속할 확률은 다음과
같다.</p>

<p>P(S∣x1,x2,…,xn)=P(x1,x2,…,xn)P(S)P(x1,x2,…,xn)P(S|x1,x2,…,xn)=\frac
{P(x1,x2,…,xn)P(S)}{P(x1,x2,…,xn)}P(S∣x1,x2,…,xn)=P(x1,x2,…,xn)P(x1,x2,…,xn)P(S)​</p>

<p>앞에서 언급했듯이 각 feature의 요소들은 조건부 독립이기 때문에 다음과
같이 바꿔 쓸 수 있다.</p>

<table>
  <tbody>
    <tr>
      <td>P(S∣x1,x2,…,xn)=P(x1∣S)P(x2∣S)…P(xn∣S)P(S)P(x1)P(x2)…P(xn)P(S</td>
      <td>x1,x2,…,xn)=\frac</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>{P(x1</td>
      <td>S)P(x2</td>
      <td>S)…P(xn</td>
      <td>S)P(S)}{P(x1)P(x2)…P(xn)}P(S∣x1,x2,…,xn)=P(x1)P(x2)…P(xn)P(x1∣S)P(x2∣S)…P(xn∣S)P(S)​</td>
    </tr>
  </tbody>
</table>

<p>위와 같이 수식을 사용하면 문서를 특정 클래스들로 분류하기 위해서는
다음만 알면 된다. <strong>1) 문서로부터 특징벡터를 추출하는 방법 2)기존에
확보된 데이터로부터 P(S∣x)P(S|x)P(S∣x)와 P(!S∣x)P(!S|x)P(!S∣x)를
계산하는 방법 3)각 클래스의 비율인 사전확률
P(S),P(!S)P(S),P(!S)P(S),P(!S).</strong> 해당 문제를 해결하기 위해 주어진
문서로 부터 판단에 사용할 특징feature를 추출해야 하는데 이때 어떤
확률분포를 사용하는지에 따라 특징벡터가 달라지게 된다.</p>

<p><a href="#%EB%82%98%EC%9D%B4%EB%B8%8C-%EB%B2%A0%EC%9D%B4%EC%A6%88-%EB%B6%84%EB%A5%98%EA%B8%B0-3%EC%A2%85%EB%A5%98"></a></p>

<p>나이브 베이즈 분류기 3종류</p>

<p>나이브 베이즈 분류기에는 다음과 같이 3 종류가 있다. 세가지를 모두
다루지는 않고 인턴 기간동안 구현한 Bernoulli naive bayes classifier에
대해서 주로 다룰 것이다. 다만 3종류는 어떠한 것이 있고 각각의 특징과
다른점들에 대해서 간단히 설명하고 넘어가보자.</p>

<ol>
  <li>
    <p>Gaussian naive bayes classifier: 설명변수가 연속형인 경우</p>

    <ul>
      <li>연속적인 데이터에 적용 가능</li>
    </ul>
  </li>
  <li>
    <p>Multinomial naive bayes classifier: 설명변수가 범주형인 경우</p>

    <ul>
      <li>카운트 데이터(횟수)에 적용 가능</li>
    </ul>
  </li>
  <li>
    <p>Bernoulli naive bayes classifier: 설명변수가 이분형인 경우</p>

    <ul>
      <li>이진 데이터에 적용 가능.</li>
    </ul>
  </li>
</ol>

<p>Gaussian naive bayes는 주로 매우 고차원적인 데이터 세트를 다룰 때
사용된다. 나머지 두 베이즈 모델인 다항분포(Multinomial)과
베르누이(Bernoulli)는 보다 텍스트와 같은 데이터에 사용된다. 인턴하는
회사에서 요구한 업무는 문서에 대한 분류기이니 후자가 더 적합하다. 그 중,
내가 맡은 업무는 베르누이를 사용한 나이브 베이즈 문서 분류기이다.</p>

<p><a href="#bernoulli-naive-bayes-%EB%B6%84%EB%A5%98%EA%B8%B0"></a></p>

<p>Bernoulli Naive Bayes 분류기</p>

<p>일부 코드를 제시하면서 구현 로직 설명을 하겠지만 인턴 회사의 코드이므로
모든 공개가 어렵다. 또한 여기서 참고할 점은 구현 언어가 회사 내에서
개발한 새로운 언어라는 것이다. 머신러닝을 사용한 인공지능 회사인 만큼
자체적으로 로직을 짜고 데이터를 처리하기에 더 적합한 언어를 포팅하여
사용하고 있다. 따라서 큰 로직만 참고하는 것을 추천한다.</p>

<p>먼저 텍스트 분류에 크게 사용되는 베르누이 확률 분포 모형과 다항분포
모형을 비교하며 간단히 어떤 차이가 있는지 살펴보자.</p>

<p>먼저 다항분포는 표본벡터 xxx가 있다고 가정했을 때, 이것을 DDD면을 가진
주사위를 yyy번 던진 결과라고 본다. 즉, x=[1,4,0,5]x=[1, 4, 0,
5]x=[1,4,0,5]가 있을 때, 다음 표본벡터는 4면체 주사위를 10번 던져서 1인
면이 1번, 2인 면이 4번, 4인 면이 5번 나온 결과이다. KKK개의 class가
있다면 DDD개 면을 가진 주사위 KKK개가 있다고 보고, 주사위를 던진
결과로부터 1,…,K1, … ,K1,…,K중 어떤 주사위를 던졌는지 찾아내는
것이라고 이해한다. 문서 내에 특정 단어가 몇번 등장하는지에 대한 횟수를
모형화 할 수 있다.</p>

<p>베르누이분포는 xxx의 원소가 0 또는 1 값만을 가질 수 있다. 위와 다르게
독립변수는 DDD개의 독립적인 확률변수를 가지고 있는, 동전으로 구성된 동전
세트로 표현할 수 있다. 각각의 값은 0 또는 1이다. KKK개의 클래스를 가지고
있다고 할 때, 전체 D∗KD * KD∗K의 조합의 동전이 존재하며 같은 class에
속하는 D개의 동전이 하나의 동전 세트를 구성하고 이런 동전 세트가 KKK개
있다고 볼 수 있다. 즉 베르누이를 사용한 나이브 베이즈 모형은 동전 세트를
N번 던진 결과로부터 1, …, KKK 중 어느 동전 세트를 던졌는지 찾아내는
것이다. 문서 내에 특정한 단어가 포함되어 있는지의 여부로 확률을 판단할
때 주로 사용한다.</p>

<ul>
  <li>feature<em>count: 각 class k에 대해 d번째 동전이 앞면이 나온 횟수
$N</em>d,_k$</li>
  <li>feature<em>log</em>prob: 베르누이분포 모수의 로그값</li>
</ul>

<p>logμk=(logμ1,k,…,logμD,k)=(logN1,kNk,…,logND,kNk)log\mu_k =
(log\mu_1,_k,…,log\mu_D,_k) =
(log\frac{N_1,_k}{N_k},…,log\frac{N_D,_k}{N_k})logμk​=(logμ1​,k​,…,logμD​,k​)=(logNk​N1​,k​​,…,logNk​ND​,k​​)</p>

<p>NkN_kNk​는 class k에 대해서 동전을 던진 횟수이다.</p>

<hr />

<p>다음 파이썬 코드를 잠깐 훑으며 베르누이 확률분포를 사용해 나이브베이즈
분류 확률을 구하는 과적을 살펴보자.</p>

<pre><code class="language-{.language-pseudocode}">x = np.array([
[0, 1, 1, 0],
[1, 1, 1, 1],
[1, 1, 1, 0],
[0, 1, 0, 0],
[0, 0, 0, 1],
[0, 1, 1, 0],
[0, 1, 1, 1],
[1, 0, 1, 0],
[1, 0, 1, 1],
[0, 1, 1, 0]])

y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]) //class 분류
</code></pre>

<p>클래스는 0과 1로 총 2개라고 본다. xxx는 확률변수를 가지고 있는 동전
세트로 볼 수 있고, yyy는 각 세트에 대한 클래스를 정의해 놓은 것이다.
처음 4개 세트는 class 0, 다음 6개 세트는 class 1이다.</p>

<p>각 클래스 kkk별, 독립변수 ddd별로 총 8개의 베르누이 확률변수의 모수를
구하면 다음과 같다. (각 클래스 별로 합치는 것)</p>

<pre><code class="language-{.language-pseudocode}">array([[2, 4, 3, 1],
       [2, 3, 5, 3]])
</code></pre>

<p>[2,4,3,1][2, 4, 3, 1][2,4,3,1]이 어떻게 나왔는지 간단하게 설명해보겠다.
xxx의 첫번 째 4 세트가 class 0이므로 각각 첫번째 요소가 1인 횟수를
더하여서 2, 두번째 요소가 1인 횟수를 더하여서 4, … 이렇게 합친다.</p>

<p>이렇게 합쳐진 요소들에 대해서 각 클래스의 전체 개수로 나누어 주어야
한다. 위 예시의 경우 class 0의 전체 개수는 4이고 1의 전체 개수는 6이다.
결과는 다음과 같다.</p>

<pre><code class="language-{.language-pseudocode}">array([[0.5,   1,   0.75,    0.25],
       [0.333, 0.5, 0.83333, 0.5]])
</code></pre>

<p>여기서 이제 <strong>스무딩(Smoothing)</strong>을 해야한다. 표본 데이터의 수가 그렇지
않음에도 불구하고 0 또는 1이라는 극단적인 값이 나오게 된다. (현실에서
그런 확률은 거의 없다) 따라서 이런 현상을 방지하기 위해서 베르누이는
모수가 0.5인 가장 일반적인 경를 가정하여서 0이 나오는 경우와 1이 나오는
경우의 가장 표본 데이터를 추가하여 스무딩한다. 주로 smoothing은 가중치
α\alphaα의 값으로 스무딩을 조절한다. 이것을 <em>==라플라스 스무딩(Laplace
smooting)==</em> 또는 <em>==애드원(Add-One) 스무딩==</em>이라고 한다.</p>

<p>μd,k=Nd,k+αNk+2α\mu_d,_k = \frac {N_d,_k + \alpha} {N_k +
2\alpha}μd​,k​=Nk​+2αNd​,k​+α​</p>

<p>위에서 스무딩 가중치 α\alphaα를 1.0을 주었을 때 결과 값은 다음과 같다.
확인해보면 1과 같은 극단적인 값이 없어졌음을 볼 수 있다.</p>

<pre><code class="language-{.language-pseudocode}">array([[0.5,   0.833333, 0.66667, 0.33333],
       [0.375, 0.5,      0.75,    0.5]])
</code></pre>

<p>예측을 하기 위해 [0,0,1,1][0, 0, 1, 1][0,0,1,1] 을 입력하면
array([0.0953,0.9046])array([0.0953 , 0.9046])array([0.0953,0.9046])
값이 나온다. 즉 3, 4번 키워드가 포함되어 있다면 class 1 일 확률이
90%라는 의미이다.</p>

<p><a href="#implementation---%EB%AC%B8%EC%84%9C-%EB%B6%84%EB%A5%98%EA%B8%B0-%EA%B5%AC%ED%98%84"></a></p>

<p>Implementation - 문서 분류기 구현</p>

<p>원리를 이해했다면 구현은 생각보다 간단하다. 물론 파이썬의 sklearn등의
모듈을 사용하면 나이브 베이즈와 각 확률분포에 대한 기능이 모두 구현되어
있다. 따라서 가져가 쓰기면 하면 된다. 여기서는 문서분류기에 해당
알고리즘을 모듈을 사용하지 않고 어떻게 구현해야 하는지를 다룰 것이다.
앞서 말했든 사내에서 쓰는 언어를 사용한 것이 때문에 코드구현은 플로우만
참고하는 것을 추천한다.</p>

<p><a href="#%ED%95%99%EC%8A%B5-learn"></a></p>

<p>학습 Learn</p>

<ul>
  <li>Input: 텍스트, 분류 클래스</li>
  <li>문서 키워드를 추출한다. 키워드 추출은 사용자마다 다른 기능이나
모듈을 가져와서 기준에 따라 추출할 수 있다.</li>
  <li>중복 제거를 위해 추출된 키워드를 Set에 입력시킨다.</li>
  <li>클래스 횟수가 저장되어 있는 자료구조에 해당 클래수 횟수를 1
증가시킨다.</li>
  <li>해당 클래스의 해당 단어의 여부를 기록하기 위해 해당 자료구조에 1을
더한다.</li>
  <li>전체 단어를 저장하는 자료구조에 단어를 추가한다.</li>
</ul>

<p>위에서 설명한 베르누이 확률분포를 계산하기 위한 Nd,kN_d,_kNd​,k​와
NkN_kNk​를 계산하는 과정으로 이해하면된다. 다음은 해당을 특정 언어로
코딩한 일부분이다. 여기서 m<em>n</em>cls와 m<em>n</em>cls<em>word등의 자료구조는 hash이고
m</em>words는 set이다.</p>

<pre><code class="language-{.language-c++}">void BernoulliModel::learn(string text, string cls){
    list&lt;string&gt; tok;
    tok = extract_words(text.trim(), m_lang, m_charset;
    m_n_cls[cls] +=1;
                        
    set&lt;string&gt; word_set;
    string word;
    for word in tok {
        word_set.add(word);
    }                    
    
    for word in word_set {
        m_n_cls_word[cls+"_"+word] += 1;
        m_words.add(word);
    }                    
}
</code></pre>

<p><a href="#%EC%98%88%EC%B8%A1-predict"></a></p>

<p>예측 Predict</p>

<ul>
  <li>Input: 예측할 테스트, Smoothing을 위한 α\alphaα</li>
  <li>입력 텍스트에 대해서 키워드를 추출함</li>
  <li>클래쓰 목록을 가져와서 각 클래스마다 다음을 반복함(해당 클래스의
Score를 구함)</li>
  <li>분모에 총 클래스 횟수와 smoothing값을 더함.</li>
  <li>추출된 각 키워드에 대해서 확률분포값과 smoothing 값을 더하여서 위의
분모로 나눈 log를 계산함(위에 베르누이 확률 계산 공식을 참고)</li>
  <li>각 클래스의 점수를 누적하여 예측함.</li>
</ul>

<pre><code class="language-{.language-pseudocode}">BernoulliModel::predict(string fe, string lang, string charset, hash&lt;string,double&gt;&amp; score_hash, double alpha){
    list&lt;string&gt; tok;
    list&lt;string&gt; cls_list;
    double denom;
    double score;
    string cls;
    string t;
    
    tok = extract_word(fe.trim(), lang, charset);
    cls_list = m_n_cls.key();
    
    for cls in cls_list {
        socre = 0.0;
        denom = double(m_n_cls[cls]) + 2*alpha;
        for t in tok{
            score += log(m_n_cls_wor[cls+"_"+t]+alpha) / denom);
        }
        score_hash[cls] += score;
    }
}
</code></pre>

<p>다음을 예측해서 Score가 가장 높은 cls 소속임을 예측한다. 다항분포
모델이랑 비교하여 새로 구현한 베르누이 나이브 베이즈 문서 분류기의
성능을 테스트 해 보았을 때 81~82% 정도의 정확성을 보이는 것을 확인했다.
다항분포는 84~85%정도의 성능이었던 것을 고려해보면 확실히 정확한
횟수보다 여부만을 가지고 계산하는 베르누이 분류기의 성능이 다소 떨어지는
것을 확인할 수 있었다.</p>

<ul>
  <li>결과:</li>
</ul>

<p><a href="/static/adc092bf4b98644a4cd46e8df3167bf9/533c1/Bernoulli.png"><img src="/static/adc092bf4b98644a4cd46e8df3167bf9/533c1/Bernoulli.png" alt="Bernoulli
result" title="Bernoulli result" /></a></p>

<p><strong>[참고
자료]:</strong>  <a href="https://nbviewer.jupyter.org/github/metamath1/ml-simple-works/blob/master/naive/naive.ipynb">https://nbviewer.jupyter.org/github/metamath1/ml-simple-works/blob/master/naive/naive.ipynb</a>,
<a href="https://wikidocs.net/22892">https://wikidocs.net/22892</a>, <a href="https://heung-bae-lee.github.io/2020/04/14/machine_learning_07/">https://heung-bae-lee.github.io/2020/04/14/machine_learning_07/</a></p>


	  ]]></description>
	</item>

	<item>
	  <title>TDD, 리펙토링이란?</title>
	  <link>//tdd</link>
	  <author></author>
	  <pubDate>2021-02-21T10:18:00+00:00</pubDate>
	  <guid>//tdd</guid>
	  <description><![CDATA[
	     <h2 id="test-driven-development테스트-주도-개발-tdd">Test Driven Development(테스트 주도 개발, TDD)</h2>

<ul>
  <li>Production Code : 프로그램 구현을 담당하는 부분으로 사용자가 사용하는 소스 코드</li>
  <li>Test code : 프로덕션 코드가 정상적으로 동작하는지 확인하는 코드</li>
</ul>

<h3 id="tdd란">TDD란?</h3>

<p>TDD = TFD(Test First Development) + 리팩토링</p>

<p>설계를 한번에 몰아서 하는 것이 아니라, 작은 단위로 자주 하자는 것</p>

<p>TDD를 잘 하려면 먼저 요구사항 분석을 잘 해야 한다 → TDD는 테스트 기술이 아니다 !</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TDD</span><span class="err">는</span> <span class="err">분석</span> <span class="err">기술이며</span> <span class="err">설게</span> <span class="err">기술이기도</span> <span class="err">하다</span><span class="o">.</span> 
<span class="n">TDD</span><span class="err">란</span> <span class="err">프로그래밍</span> <span class="err">의사결정과</span> <span class="err">피드백</span> <span class="err">사이의</span> <span class="err">간극을</span> <span class="err">의식하고</span> <span class="err">이를</span> <span class="err">제어하는</span> <span class="err">기술이다</span><span class="o">.</span> 
</code></pre></div></div>

<p><img src="TDD,%20%E1%84%85%E1%85%B5%E1%84%91%E1%85%A6%E1%86%A8%E1%84%90%E1%85%A9%E1%84%85%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B5%E1%84%85%E1%85%A1%E1%86%AB%20eebf5e3b124e4a9cb8805add9639afcf/_2021-02-16__11.43.25.png" alt="TDD,%20%E1%84%85%E1%85%B5%E1%84%91%E1%85%A6%E1%86%A8%E1%84%90%E1%85%A9%E1%84%85%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B5%E1%84%85%E1%85%A1%E1%86%AB%20eebf5e3b124e4a9cb8805add9639afcf/_2021-02-16__11.43.25.png" /></p>

<ul>
  <li>TDD 원칙
    <ol>
      <li>실패하는 단위 테스트를 작성할 때까지 프로덕션 코드를 작성하지 않음</li>
      <li>컴파일은 실패하지 않으면서 실행에 실패하는 정도로만 단위 테스트를 작성</li>
      <li>현재 실패하는 테스트를 통과할 정도로만 실제 코드를 작성</li>
    </ol>
  </li>
</ul>

<h3 id="tdd에-집착하는-이유">TDD에 집착하는 이유</h3>

<ul>
  <li>요구사항 추가, 변경 때문에 소스코드를 수정하면서 불안하게 살지 않을 수 있다</li>
  <li>주로 한번에 한 가지만 집중할 수 있다</li>
  <li>
    <p>처음부터 완벽한 설계를 하는 것보다 점진적으로 설계를 개선해 나갈 수 있다</p>
  </li>
  <li>
    <p>Test Fail → Test pass 가 되면 우선 심리적 안정감을 느낀다</p>

    <p>⇒ 이때 창의적으로 안정적인 설계 리팩토링을 할 수 있다.</p>
  </li>
  <li>빠른 피드백으로 개발 효율성을 높인다
    <ul>
      <li>버그를 찾는 시점이 매우 빨라진다</li>
      <li>일정한 리듬을 통해서 프로그래밍에 재미를 느낄 수 있다</li>
      <li>더 많은 삽질을 할 수 있다 → 더 많은 것을 배울 수 있다 (ㅋㅋ)</li>
    </ul>
  </li>
  <li>수동 테스트, 배포에 대한 부담을 줄이면서 핵심적인 비지니스 로직 구현에 집중할 수 있다</li>
</ul>

<p>지금 필요한 것은 새로운 접근방식에 도전할 수 있는 용기 😃</p>

<h2 id="tdd로-자동차-경주-게임-구현">TDD로 자동차 경주 게임 구현</h2>

<hr />

<h3 id="처음-tdd-단위-테스트를-시작할-때-">처음 TDD, 단위 테스트를 시작할 때 …</h3>

<p>도대체, 어디서, 어떻게, 무엇으로 시작해야할지 모르겠다 ! 감이 안 잡힌다 !</p>

<h3 id="자동차-경주-게임에-적용하기">자동차 경주 게임에 적용하기</h3>

<ul>
  <li>먼저 요구사항 분석으로 대략적인 설계를 한다 ⇒ 객체를 추출</li>
  <li>UI, DB와 의존관계를 가지지 않는 핵심 도메인 모델(핵심 비지니스 로직을 가지는) 영역에 집중
    <ul>
      <li>일단 뷰나 컨트롤러에 대한 테스트는 어렵고 지금 단계에서는 안해도 될 것 같다 (1차적으로)</li>
    </ul>
  </li>
</ul>

<ol>
  <li><strong>우선 구현할 기능 목록 작성하기</strong></li>
  <li>그래도 막막하다면,,
    <ul>
      <li>우선 일단 구현하고, 도메인 지식을 쌓는다</li>
      <li>이후에 구현한 코드를 버리고, 다시 기능 목록 작성 및 TDD 구현으로 시작한다.</li>
      <li>코드를 버리는 것을 아까워 하지 마라!</li>
      <li>아무것도 없는 상태에서 새롭게 구현하는 것이 레거시 코드를 리팩토링 하는 것보다 쉽다</li>
    </ul>
  </li>
</ol>

<h3 id="실제-자동차-게임-구현해보기">실제 자동차 게임 구현해보기</h3>

<ol>
  <li>일단 구현해보기</li>
  <li>TDD가 가능한 부분을 찾아서 단위 테스트 하기
    <ul>
      <li>자동차 이동 유무 등등</li>
    </ul>
  </li>
  <li>테스트하기 어려운 부분을 찾아서 가능한 구조로 개선하기
    <ul>
      <li>어떻게 판단하느냐?
        <ul>
          <li>Object Graph에서 다른 Object에 의존하지 않는 가장 마지막 노드를 찾는다.</li>
          <li>예) RacingMain → RacingGame → Car에서 Car 가 테스트 가능 한가?</li>
          <li>만약 Car에서 랜덤 인풋을 사용한다면 테스트하기 어렵다.</li>
        </ul>
      </li>
      <li>해결책
        <ul>
          <li>테스트가 어려운 코드의 의존관계를 object graph의 상위로 이동한다.</li>
          <li>즉, 언젠가는 테스트 하기 어려운 코드가 생기지만, 테스트 할 수 있는 영역이 넓어진다</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p><img src="TDD,%20%E1%84%85%E1%85%B5%E1%84%91%E1%85%A6%E1%86%A8%E1%84%90%E1%85%A9%E1%84%85%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B5%E1%84%85%E1%85%A1%E1%86%AB%20eebf5e3b124e4a9cb8805add9639afcf/_2021-02-16__12.13.25.png" alt="TDD,%20%E1%84%85%E1%85%B5%E1%84%91%E1%85%A6%E1%86%A8%E1%84%90%E1%85%A9%E1%84%85%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B5%E1%84%85%E1%85%A1%E1%86%AB%20eebf5e3b124e4a9cb8805add9639afcf/_2021-02-16__12.13.25.png" /></p>

<ul>
  <li>테스트하기 어려운 코드들
    <ul>
      <li>내부 API
        <ul>
          <li>외부 세계 : 외부 REST API, 데베 API</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="라이브-코딩으로-tdd-학습하기">라이브 코딩으로 TDD 학습하기</h2>

<hr />

<ol>
  <li>
    <p>먼저 Test Code를 작성한다</p>

    <ul>
      <li>이때 당연하게 컴파일 에러가 생긴다</li>
    </ul>
  </li>
  <li>
    <p>우선 존재하는 컴파일 에러를 모두 해결한다.</p>

    <ul>
      <li>이후에 실행해보면 우선 테스트는 실패한다! (1단계 : 실패하는 테스트)</li>
    </ul>
  </li>
  <li>이후에 우선 테스트를 패스하도록 한다.
    <ul>
      <li>제대로된 로직을 구현하지 않아도 꼼수를 통해서 우선 패스 하도록 한다</li>
      <li>최대한 초록불을 빨리 보자! (2단계 : 테스트 패스)</li>
    </ul>
  </li>
  <li>리팩토링 하도록 한다
    <ul>
      <li>이름 바꾸기 등등</li>
    </ul>

    <p>처음에만 ctrl shitf R이고 이후에는 ctrl R 만 누르면 직전 코드를 실행한다.</p>
  </li>
  <li>추가 다른 경우 테스트를 추가했을 때 실패하게 된다. 이때 이제 로직을 점차적으로 수정해간다.
    <ul>
      <li>설계 개선을 고민한다!!</li>
      <li>이때 설계를 개선한다.</li>
      <li>이때 생각을 바꾸는 과정을 거치는 것이다. (어렵다.. ㅠ)</li>
    </ul>

    <p>테스트 코드도 리팩토링이 필요하다 ! 중복을 없애고 더 효율적으로 개선하라.</p>
  </li>
</ol>

<p>만약 프로덕션 코드를 구현하는 도중에 크게 리팩토링 해야할 부분들이 보이면 꾹 참고 다음에 해야할까? 까먹으면 어쩌죠?</p>
<ul>
  <li>TODO 리스트를 만들어서 지속적으로 업데이트 하는 것을 추천 한다.</li>
  <li>처음에 한번만 만들어서 그것만 해치우는 것이 아니라 중간에 생긴 것들을 추가하여 구현하도록 한다.</li>
</ul>

<p>안좋은 커밋 습관이 컴파일 되지 않는 코드를 커밋하는 것이다. 
기본 규칙은 반드시 컴파일 되는 코드를 커밋하는 것이다. 
리팩토링 연습을 위한 커밋 단위도 추천한다 
→ 대대적인 리팩토링을 하기 전에 커밋을 하여, 실패했을 경우 다시 되돌려서 다시 리팩토링을 할 수 있으니까!</p>

	  ]]></description>
	</item>


</channel>
</rss>
